{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "45feaa06-246d-4db5-b396-4ae03955cf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "e834f670-8e0a-42c9-8feb-0fe693496976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75f91d4-59c4-4327-b3d3-eeb2c4f1a95a",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bf124b6-cf70-4fbf-aea1-45aaadb412f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the file\n",
    "filepath = '../data/input.txt'\n",
    "if not os.path.exists(filepath):\n",
    "    data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(requests.get(data_url).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b7cb886-719a-4eea-b5aa-c8bd73c9ab86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "# Reading the file\n",
    "with open(filepath) as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(raw_text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "448f2fc4-c7a1-4907-800a-3ad80ca94483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 65\n",
      "encode.    hello   => [46, 43, 50, 50, 53, 2]\n",
      "decode.    [46, 43, 50, 50, 53, 2]   => hello!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ordered list of all characters in the corpus\n",
    "vocab = sorted(list(set(raw_text)))\n",
    "vocab_size = len(vocab)\n",
    "print(f'vocab_size: {vocab_size}')\n",
    "\n",
    "# dictionaries to convert chars to ints, and viceversa\n",
    "itos = {i:v for i,v in enumerate(vocab)}\n",
    "stoi = {v:i for i,v in enumerate(vocab)}\n",
    "\n",
    "# functions to tokenize sequences of arbitrary length\n",
    "encode = lambda x : [stoi[s] for s in x]\n",
    "decode = lambda x : ''.join([itos[i] for i in x])\n",
    "\n",
    "hello_encoded = encode('hello!')\n",
    "hello_decoded = decode(hello_encoded)\n",
    "print(f'encode.    hello   => {hello_encoded}')\n",
    "print(f'decode.    {hello_encoded}   => {hello_decoded}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cdda0100-1254-4c05-831b-cbc55704ef28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1115394])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing the text an creating a numerical tensor\n",
    "token_text = torch.tensor(encode(raw_text))\n",
    "token_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de3660e2-505c-4400-b2b2-be7e7ff3a20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1003854]) torch.Size([111540])\n"
     ]
    }
   ],
   "source": [
    "# Splitting data in train, val\n",
    "train_size = int(0.9 * len(token_text))\n",
    "data_train = token_text[:train_size]\n",
    "data_val = token_text[train_size:]\n",
    "print(data_train.shape, data_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ddddde4b-7ceb-4a1f-b16c-92426f0fdc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing training batches\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "batch_size = 4   # the number of sample processed in the same batch\n",
    "block_size = 8   # the length of the sequence of character used by the model to predict the next character\n",
    "\n",
    "def get_batch(data, batch_size, block_size):\n",
    "\n",
    "    # generating the start index of  batch_size independent samples\n",
    "    idx = torch.randint(len(data)-block_size, (batch_size,))\n",
    "\n",
    "    # extracting the xi, each having block_size elements\n",
    "    x = torch.stack([data[i:i+block_size] for i in idx])\n",
    "\n",
    "    # extracting the yi, the next characters\n",
    "    y = torch.stack([data[i+1:i+1+block_size] for i in idx]) \n",
    "    return x, y\n",
    "\n",
    "x_train, y_train = get_batch(data_train, batch_size, block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2c7f158e-8dfb-4ee6-8deb-2d83564a0553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_train)\n",
    "print()\n",
    "print(y_train.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78f6934-a4aa-42ef-aa38-4095a1f10dc1",
   "metadata": {},
   "source": [
    "# Creating models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705c2bc9-e0d6-4ca6-8ce0-1cdef5522800",
   "metadata": {},
   "source": [
    "## Bigram model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5ba49595-2bc7-4d7e-85c3-701e994048e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts next character using only the previous character\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # A table mapping the index of each character, to the logits distribution of the next character\n",
    "        # The element E[i,j] represent the logit associated to next character being j, when the current \n",
    "        # character is i\n",
    "        self.E = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, X, y=None):\n",
    "\n",
    "        # extracting the logits of the next character, for each character in the input\n",
    "        # The shape of the input is (batch_size, block_size)\n",
    "        # The shape of the output is (batch_size, block_size, vocab_size)\n",
    "        logits = self.E(X)\n",
    "\n",
    "        # computing loss, only when a target y is provided\n",
    "        if y is not None:\n",
    "            # reshaping logits, and target to match the expected shapes of the cross_entropy function\n",
    "            batch_size, block_size, vocab_size = logits.shape\n",
    "            logits = logits.view((batch_size*block_size, vocab_size))\n",
    "            y = y.view(batch_size*block_size)\n",
    "            \n",
    "            # computing the loss\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "        else:\n",
    "            loss = None\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, X, max_length=100):\n",
    "\n",
    "        for i in range(max_length):\n",
    "            # performing a forward pass\n",
    "            logits, loss = self.forward(X)\n",
    "    \n",
    "            # condsidering only the last character of each sequence\n",
    "            logits = logits[:, -1, :]\n",
    "    \n",
    "            # computing probs, from the logits\n",
    "            probs = logits.softmax(dim=-1)\n",
    "    \n",
    "            # sampling from the probability distributions\n",
    "            new_element = torch.multinomial(probs, 1)\n",
    "    \n",
    "            # attaching the new elements to the context\n",
    "            X = torch.concat((X, new_element), axis=1)\n",
    "\n",
    "        # Decoding the generated sequences\n",
    "        res = [decode(X[i].tolist()) for i in range(X.shape[0]) ]\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e164e577-5b86-403c-ad07-e01e25e6d903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 65]), tensor(4.7027, grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(x_train, y_train)\n",
    "logits.shape, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "724f4af3-bd59-4db4-9119-faee516b875e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".Y:pb,xY;?\n",
      "zBblo GCGv;\n",
      "K:sC?KugUDt\n",
      "ED;Dtj;Dc$ab!avNsl,pAfdEqOfbzmSo!&iTjxFoCIyHSmy;zwU3p3b?:EMIy PAW\n"
     ]
    }
   ],
   "source": [
    "# Generating sequence from UNTRAINED model\n",
    "\n",
    "# creating initial context\n",
    "context = torch.zeros((1, 1)).int()\n",
    "\n",
    "# generating sequence of arbitrary length \n",
    "res = m.generate(context, max_length=100)\n",
    "\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4f0b7d6f-0917-4012-bd59-2a0e1785ef96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6096601486206055\n",
      "3.907146453857422\n",
      "3.3213071823120117\n",
      "2.8333771228790283\n",
      "2.9970436096191406\n",
      "2.904151439666748\n",
      "2.7995710372924805\n",
      "2.4972057342529297\n",
      "2.693941354751587\n",
      "2.48555588722229\n"
     ]
    }
   ],
   "source": [
    "# Training a model with Adam Optimizer\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=10**(-3))\n",
    "\n",
    "for i in range(10000):\n",
    "\n",
    "    # generating a random batch\n",
    "    X_b, y_b = get_batch(data_train, batch_size, block_size)\n",
    "\n",
    "    # forward pass\n",
    "    logits, loss = m(X_b, y_b)\n",
    "\n",
    "    # bacward pass\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "63dbe722-fb69-44c6-98f7-df2df2c44c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ABd hatratdir on lir o tre:\n",
      "E:\n",
      "O:\n",
      "TEY;\n",
      "Duraso.ped arerd.\n",
      "He de, I lande, ompe'sepOM3rehe IG me ake it heard zibas way nd nd hireagmbeexj?\n",
      "Lorerdithofo:\n",
      "A:\n",
      "HME:\n",
      "vpees; PW-pe Lbe warothe m s crve y;\n",
      "Nucoun ld,\n",
      "YAufotoouson Bup'do-hor haved isonderis byou:\n",
      "These l oll d d st a\n",
      "NGS:D tllatofare d:\n",
      "M3BAt h cen'd ourgor rs, f he chor wharome terelaime be s ISous mec?d; cwis o te: Q.\n",
      "dl toul, anoubesus kifrnthes,\n",
      "A r heinoun, h cis oo therer intootlinod ce whooue mons\n",
      "Bis,\n",
      "\n",
      "The celikexpas gls l o merrs\n"
     ]
    }
   ],
   "source": [
    "# Generating sequence from TRAINED model\n",
    "\n",
    "# creating initial context\n",
    "context = torch.zeros((1, 1)).int()\n",
    "\n",
    "# generating sequence of arbitrary length \n",
    "res = m.generate(context, max_length=500)\n",
    "\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6406f0ee-800e-4ddd-b9e5-f28520bf56aa",
   "metadata": {},
   "source": [
    "## Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "e6b23776-3031-4785-9275-06d8ef2fe86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "X_i = tensor([[ 3.,  5.],\n",
      "        [ 8., 10.],\n",
      "        [ 6.,  2.]])\n",
      "\n",
      "Z_i = tensor([[ 3.,  5.],\n",
      "        [11., 15.],\n",
      "        [17., 17.]])\n"
     ]
    }
   ],
   "source": [
    "# We want to create a transformation matrix that for each token, collects information for all \n",
    "# the previous tokens in the sequence.\n",
    "# Let's assume that emb_size = 2, and block_size=3\n",
    "# If we have a matrix \n",
    "#     \n",
    "# W = [[ 1, 0, 0]\n",
    "#      [ 1, 1, 0]\n",
    "#      [ 1, 1, 1]]\n",
    "#\n",
    "# and sample X_i representing a sequence of tokens of size emb size\n",
    "#\n",
    "# X_i =[[ 3, 5]       # token at time 0\n",
    "#       [ 8, 10]      # token at time 1\n",
    "#       [ 6, 2]]      # token at time 2\n",
    "#\n",
    "# then if we perform a matrix multiplication between W and  and X_i\n",
    "# we obtain \n",
    "#\n",
    "# Z_i = [[ 3, 5]      # token at time 0\n",
    "#        [11, 15]     # token at time 1\n",
    "#        [17, 17]]    # token at time 2\n",
    "# \n",
    "# where the token at time j is obtained by summing al the tokens until time j included.\n",
    "\n",
    "W = torch.tril(torch.ones((3,3)))\n",
    "print(f'W = {W}')\n",
    "\n",
    "X_i = torch.tensor([[ 3, 5],\n",
    "                    [ 8, 10],\n",
    "                    [ 6, 2]] ).float()\n",
    "print()\n",
    "print(f'X_i = {X_i}')\n",
    "\n",
    "Z_i = W @ X_i\n",
    "print()\n",
    "print(f'Z_i = {Z_i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "0b63784b-a3aa-49f1-ab4d-dc29e294a219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "\n",
      "X_i = tensor([[ 3.,  5.],\n",
      "        [ 8., 10.],\n",
      "        [ 6.,  2.]])\n",
      "\n",
      "Z_i = tensor([[3.0000, 5.0000],\n",
      "        [5.5000, 7.5000],\n",
      "        [5.6667, 5.6667]])\n"
     ]
    }
   ],
   "source": [
    "# Since we want merge into each time step the knowledge from the previous time steps\n",
    "# a simple mean would be more appropriate than a sum\n",
    "W = torch.tril(torch.ones((3,3))) \n",
    "W /= W.sum(axis=1, keepdims=True)\n",
    "print(f'W = {W}')\n",
    "\n",
    "X_i = torch.tensor([[ 3, 5],\n",
    "                    [ 8, 10],\n",
    "                    [ 6, 2]] ).float()\n",
    "print()\n",
    "print(f'X_i = {X_i}')\n",
    "\n",
    "Z_i = W @ X_i\n",
    "print()\n",
    "print(f'Z_i = {Z_i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "ccafba02-3ccc-4fb6-b2ce-93531dff7633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = tensor([[1.0000,   -inf,   -inf],\n",
      "        [0.5000, 0.5000,   -inf],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "\n",
      "X_i = tensor([[ 3.,  5.],\n",
      "        [ 8., 10.],\n",
      "        [ 6.,  2.]])\n",
      "\n",
      "Z_i = tensor([[3.0000, 5.0000],\n",
      "        [5.5000, 7.5000],\n",
      "        [5.6667, 5.6667]])\n"
     ]
    }
   ],
   "source": [
    "# In practice we want to be able to learn the matrix W by backpropagation, and not set them manually.\n",
    "# If we start from a triangular matrix, and keep updating it through backpropagation, there is no\n",
    "# guarantee that zeros will stay 0.\n",
    "# One trick to keep the triangular shape of the matrix is to replace the zeros with -inf:\n",
    "#   - no amount of change will change the -inf\n",
    "#   - when, eventually, applying a softmax to the result the -inf values will become zeros\n",
    "\n",
    "W = torch.tril(torch.ones((3,3))) \n",
    "W /= W.sum(axis=1, keepdims=True)\n",
    "W[W == 0.] = -torch.inf\n",
    "print(f'W = {W}')\n",
    "\n",
    "X_i = torch.tensor([[ 3, 5],\n",
    "                    [ 8, 10],\n",
    "                    [ 6, 2]] ).float()\n",
    "print()\n",
    "print(f'X_i = {X_i}')\n",
    "\n",
    "Z_i = W.softmax(axis=1) @ X_i\n",
    "print()\n",
    "print(f'Z_i = {Z_i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "86ee1ef9-fafb-447c-9ce8-aec0082585cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q.shape = torch.Size([40, 10])\n",
      "K.shape = torch.Size([40, 10])\n",
      "W.shape = torch.Size([40, 40])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\na = torch.randn(50,100)\\nprint(a.std(axis= 1).mean())\\nb = torch.randn(50,100)\\nprint(b.std(axis= 1).mean())\\nab = (a @ b.T) \\nprint(ab.std(axis= 1).mean())\\nab_norm = ab * 100**-0.5\\nprint(ab_norm.std(axis= 1).mean())\\n'"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9EAAAHoCAYAAABO2mw/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABjRUlEQVR4nO3deZxcZZ33/e+pqu7q7vSSfSMrCSRsCUOAkAiIEAlh5AFhHAF9CTMO3mhwbonjkhlUUGfigOMoPhG97/EGxwdEmRG4dRRUJGFLEGJCCEsgIZB9T7o73eml6lzPH0xa2yTd35NUUd2dz/v16pem+svvuk6d5Tq/ru6qKIQQBAAAAAAAupUq9QQAAAAAAOgtaKIBAAAAADDRRAMAAAAAYKKJBgAAAADARBMNAAAAAICJJhoAAAAAABNNNAAAAAAAJppoAAAAAABMNNEAAAAAAJhoooF3SBRFuvXWW+3sTTfdVNwJAQCAkuP+AOh9aKLRJ/3kJz9RFEV68MEHD/re1KlTFUWRHn/88YO+N2bMGM2cOfOdmKKeeeYZ3Xrrrdq7d+87Mp7rO9/5ju65555STwMAgII7lu8P3nzzTUVRpCiK9J//+Z8Hff/WW29VFEXauXNnQccF+iKaaPRJ5557riTpqaee6vR4Q0ODVq1apUwmo6effrrT9zZs2KANGzZ0/LeFtn//ft1yyy0d/37mmWd022230UQDAPAO4f7gbV/+8pcVQihafaCvo4lGnzRy5EiNHz/+oEVyyZIlCiHoAx/4wEHfO/DvYi2SFRUVymQyRand1zU1NZV6CgCAPoD7A+n000/XypUrD/lqfCGxdqMvo4lGn3Xuuedq+fLl2r9/f8djTz/9tE455RTNmTNHS5cuVRzHnb4XRZHe9a53HbbmnXfeqXQ63emnw//yL/+iKIo0b968jsfy+bxqamr0uc99ruOxP/6bp1tvvVWf+cxnJEnjx4/v+PWqN998s9N4Dz30kE499VRls1mdcsopeuSRRw6a0/LlyzVnzhzV1taqurpaF110kZYuXdopc+BXtP7UPffc02nccePG6aWXXtLixYs75nTBBRcc9vk48KthX//61/W//tf/0oQJE5TNZnXWWWfpueeeOyj/29/+Vuedd5769eun/v376/LLL9crr7xyyLm+/PLLuvbaazVgwICOG5dx48bpfe97nxYtWqQzzzxTlZWVOu2007Ro0SJJ0k9/+lOddtppqqio0LRp07R8+fLDzh0AcGw6Vu4PDufqq6/WiSeeaL8a/cADD2jatGmqrKzU4MGD9eEPf1ibNm3qlLn++utVXV2ttWvX6tJLL1VNTY0+9KEPdWzfTTfdpAceeEAnn3yyKisrNWPGDL344ouSpO9973uaOHGiKioqdMEFFxy0rUBPRBONPuvcc89Ve3u7nn322Y7Hnn76ac2cOVMzZ85UfX29Vq1a1el7kydP1qBBgw5b87zzzlMcx51+Sv3kk08qlUrpySef7Hhs+fLl2rdvn84///xD1rnyyit1zTXXSJL+9V//VT/84Q/1wx/+UEOGDOnIPPXUU/rEJz6hq6++WrfffrtaWlp01VVXadeuXR2Zl156Seedd55eeOEFffazn9UXvvAFrVu3ThdccEGn7XZ985vf1KhRozR58uSOOf3DP/xDt//dfffdpzvuuEP/43/8D331q1/Vm2++qSuvvFLt7e0dmd/85jeaPXu2tm/frltvvVXz5s3TM888o3e9612HXDA/8IEPqLm5Wf/0T/+kG264oePxNWvW6Nprr9Vll12mBQsWaM+ePbrssst077336uabb9aHP/xh3XbbbVq7dq3+8i//stONEAAAx8L9QVfS6bRuueUWvfDCC92+Gn3PPffoL//yL5VOp7VgwQLdcMMN+ulPf6pzzz33oF83z+Vymj17toYOHaqvf/3ruuqqqzo9F5/+9Kd13XXX6dZbb9Urr7yi973vfVq4cKHuvPNOfeITn9BnPvMZLVmyRH/9139tbQdQUgHoo1566aUgKXzlK18JIYTQ3t4e+vXrF37wgx+EEEIYNmxYWLhwYQghhIaGhpBOp8MNN9zQZc18Ph9qa2vDZz/72RBCCHEch0GDBoUPfOADIZ1Oh8bGxhBCCN/4xjdCKpUKe/bs6fhvJYUvfelLHf++4447gqSwbt26g8aRFMrLy8OaNWs6HnvhhReCpPDtb3+747ErrrgilJeXh7Vr13Y8tnnz5lBTUxPOP//8jse+9KUvhUOd7nffffdBczjllFPCu9/97i6fhwPWrVsXJIVBgwaF3bt3dzz+8MMPB0nhZz/7Wcdjp59+ehg6dGjYtWtXp21KpVLhIx/5yEFzveaaaw4ab+zYsUFSeOaZZzoee/TRR4OkUFlZGd56662Ox7/3ve8FSeHxxx+3tgUAcGw4Fu4PDuXAmn3HHXeEXC4XTjjhhDB16tQQx3EI4Q/r744dO0IIIbS1tYWhQ4eGU089Nezfv7+jzs9//vMgKXzxi1/seOy6664LksLnP//5Q845m8122p4Da/Tw4cNDQ0NDx+Pz588/7LYDPQmvRKPPOumkkzRo0KCOnwq/8MILampq6nh3zZkzZ3a8eciSJUuUz+e7/XunVCqlmTNn6oknnpAkvfLKK9q1a5c+//nPK4SgJUuWSHr7J66nnnqq+vfvf8TznzVrliZMmNDx7ylTpqi2tlZvvPGGpLd/JexXv/qVrrjiCh1//PEduREjRujaa6/VU089pYaGhiMeP4kPfvCDGjBgQMe/zzvvPEnqmOuWLVu0YsUKXX/99Ro4cGBHbsqUKXrve9+rX/ziFwfVvPHGGw851sknn6wZM2Z0/Hv69OmSpAsvvFBjxow56PEDcwAAQOr79weOP341+qGHHjpk5vnnn9f27dv1iU98QhUVFR2P//mf/7kmT56s//qv/zrov/n4xz9+yFoXXXSRxo0b1/HvA2v0VVddpZqamoMeZ+1GT0cTjT4riiLNnDmz42+bnn76aQ0dOlQTJ06U1HmRPPC/zpuGnHfeeVq2bJn279+vJ598UiNGjNAZZ5yhqVOndvzK1lNPPdXRSB6pP24IDxgwYID27NkjSdqxY4eam5s1adKkg3InnXSS4jjWhg0bjmoOrj+d64GG+sBc33rrLUk67Fx37tx50BuQjB8/3hqrrq5OkjR69OhDPn5gDgAASH3//sD1oQ99SBMnTjzs30Z3tXZPnjy54/sHZDIZjRo1ypozazd6O5po9Gnnnnuu6uvr9eKLL3b8vdMBM2fO1FtvvaVNmzbpqaee0siRIzu9ottVzfb2di1ZskRPPvlkx2J43nnn6cknn9Srr76qHTt2HPUimU6nD/n4oRa67hzqTcWkt1/NLoRCzvWAysrKRGMVYw4AgL6J+4M/vBq9YsUKPfzww0c1J0nKZrNKpQ7dWrB2o6+hiUaf9sefB/n00093emfNadOmKZvNatGiRXr22We7fNfNP3b22WervLxcTz75ZKdF8vzzz9ezzz6rxx57rOPfXTlcY+saMmSIqqqqtHr16oO+9+qrryqVSnX8hPfAK8N/+iYgf/pT5ELM61DGjh0rSYed6+DBg9WvX7+CjwsAwKH05fuDJD784Q9r4sSJuu222w5qXLtau1evXt3xfeBYRBONPu3MM89URUWF7r33Xm3atKnTT5qz2azOOOMMLVy4UE1NTfbnP1ZUVOiss87Sj370I61fv77TT5r379+vO++8UxMmTNCIESO6rHOgafzTxtaVTqd18cUX6+GHH+707tbbtm3Tfffdp3PPPVe1tbWS1PG3Uwf+Vkt6+/Mbf/CDHxxyXkc6p8MZMWKETj/9dP3gBz/oVHvVqlX61a9+pUsvvbSg4wEA0JW+fH+QxB+/Gv1//+//7fS9M888U0OHDtV3v/tdtba2djz+y1/+Uq+88or+/M//vOjzA3oqmmj0aeXl5TrrrLO0ZMkSZbNZTZs2rdP3Z86c2fFmH+4iKb29IK5evVp1dXU67bTTJElDhw7VpEmT9Nprr1m/qnVgLv/wD/+gH/7wh7r//vsP+rvg7nz1q19VJpPRueeeq3/6p3/S7bffrpkzZ6q1tVW33357R+7iiy/WmDFj9NGPflS33367/uVf/kVnn312p4/M+ON5rVy5Ul/96ld1//3367e//W2iOR3OHXfcoV27dmnGjBn6+te/rq985Su68MILVVdX1/H5mAAAvBP6+v1BEh/60Ic0YcIErVixotPjZWVl+ud//metXLlS7373u/Wtb31Lf//3f6+/+Iu/0Lhx43TzzTcXbU5AT0cTjT7vwOJ34Nez/tiBX9GqqanR1KlT7ZoHFsGZM2d2+vufP/6pc3fOOussfeUrX9ELL7yg66+/Xtdcc4127Nhhz0GSTjnllI53+lywYIFuu+02jR07Vo8//njHO1xKby+EDz74oCZMmKAvfOELuvPOO/U3f/M3uummmw6q+cUvflGXXnqpbr/9dl1zzTX68pe/nGhOhzNr1iw98sgjGjRokL74xS/q61//us455xw9/fTTh30TMQAAiqUv3x8kkclkdMsttxzye9dff71+/OMfq62tTZ/73Of0ve99T+9///v11FNPHdU7jAO9XRT4y30AAAAAACy8Eg0AAAAAgIkmGgAAAAAAE000AAAAAAAmmmgAAAAAAEw00QAAAAAAmGiiAQAAAAAwZUo9gT8Vx7E2b96smpoaRVFU6ukAAKAQghobGzVy5MhOn/2KI8d6DwDoSZKs9T2uid68ebNGjx5d6mkAAHCQDRs2aNSoUaWeRp/Aeg8A6Imctb5oTfTChQt1xx13aOvWrZo6daq+/e1v6+yzz+72v6upqZEknatLlVFZ9wOl0t6E4ryXK1ZNV7F+Gh9Cceo6irFNpdweyT9GJCnEZq4I25RknsU4nhOIMt7lKOQTzDPBc5qurbFy+YZGf/w+6EO/32Dl7j0jQXPkXiNKeN7n1K6n9IuONQpvO9K1XvrDen9+1V8oE3W/3kfDh3qT2tvg5SSpztufYccuu2Roa7dy6ZHD7JpJxNt3WrmozL8FDO05K5caMsiuqZx3LQ/N++2ScYLrc5Qtt3KpoYPtmq545247666NGjTArhm27fDHr6z0gu3ecS9JGuY9p9G+Zruke95JUn6sdy3JbPDOpSRCS4LjuanFyqX6VfgTyHjHvSSt+9gEKzf2X1bYNdODB1q5sN/bdkkKzd5xEpV3v+250KbFjT+x1vqiNNE//vGPNW/ePH33u9/V9OnT9c1vflOzZ8/W6tWrNXRo1wfugV/pyqjMWlQVmU1ClODX74pR0x67WL/S1sea6FJuj+QfI5Iks4kuxjYlmWcxjucEoshsohPNM0ETHXkLS+Rcl/qwqmrvmLKu3wfY14gSnvf/PTS/dvwHR7PWS3+03kdlyhjnX5TOehNL+TeJMmsG8/rwdtYcOmVuT0KxfS1L0ESb191Ukm1KmU20mZOkOMF1JzKfp0TbZHL3kZRgP7nnh5Idz5F7PiW5NppzjRLs+5Dyx48yXtOZSXItMYUoyfHsZVMJ9meS62O6wnyeEpx37nUvpNx7ZylE3g/53HP+7Wz3x1NR7pq/8Y1v6IYbbtBf/dVf6eSTT9Z3v/tdVVVV6f/8n/9TjOEAAMA7jLUeAHCsKngT3dbWpmXLlmnWrFl/GCSV0qxZs7RkyZKD8q2trWpoaOj0BQAAeq6ka73Eeg8A6DsK3kTv3LlT+Xxew4Z1/lufYcOGaevWrQflFyxYoLq6uo4v3mQEAICeLelaL7HeAwD6jpJ/Tsf8+fNVX1/f8bVhg/emNQAAoPdgvQcA9BUFf2OxwYMHK51Oa9u2bZ0e37Ztm4YPH35QPpvNKpstzptrAACAwku61kus9wCAvqPgr0SXl5dr2rRpeuyxxzoei+NYjz32mGbMmFHo4QAAwDuMtR4AcCwrykdczZs3T9ddd53OPPNMnX322frmN7+ppqYm/dVf/VUxhgMAAO8w1noAwLGqKE30Bz/4Qe3YsUNf/OIXtXXrVp1++ul65JFHDnoDki5FkfeZc2eebJVrHeJ/EHn2v57zggk+Ey89yPtw8fzOXXbNzLgxdrZtlDd+6qkVdk1bKPxnu0YJfiUwtLYWfHzF/uf8lVTwP2cvCft43rW78GMPHGBnk4wfVVV6wSK8o3CUSfB5rXnz2Ety3iW4lt09eZxXssz/3MjQ3mZn0XMUZK2XlKquVsr47NKW0d65n584yB678vEXrVxqQH+7ZjzMe8O0/Etr7Jph2mQ72368t/3Zp17yx897a0l+4xa7ZpT2fhkyGj3Srql9TX7WvEaG+gTX/Hbv82rlXsclyVwfokZ/20Oc4DN4h3vHU7R5p10zatpv5eJBtXZNvfamP37O2/7Q5q9NocW710wN8a9P6UrvviS0t9s1leDztI//jneNikYe+k94DiX31kYrlx5QZ9dUyruWOPdPIfjnZlGaaEm66aabdNNNNxWrPAAAKDHWegDAsajk784NAAAAAEBvQRMNAAAAAICJJhoAAAAAABNNNAAAAAAAJppoAAAAAABMNNEAAAAAAJhoogEAAAAAMNFEAwAAAABgypR6AocVgqTQbSz96ltWubLsBH/sVNrLxXm7ZH7nLn98075Th9vZip//ruDjl1JobS31FHqH0P05dCTyu/cUvGbI5Uo2tiTltm6zcuFdp9s1o6dXeDXNbZfkX5+Cf31Kcpy0zT7TypU/+rw/fgmlJ020ciHfKr1e5Mkco0IICsYxmNnXZtVrHVhljx2NGmHlcmvftGum29u9sav72TX3jPe3acB/vewFa2rsmmFvvZfL+9cdNxu9udGv2e4dI5KUHuHdQ8X7muyaUUWFV7Ox0a6ZSnvX/FDv3xdF2ayf3dVg5fINXk6SInP7U7kE61hdrR0Nb26xco3vPsGuWfObV7xgu7/eh2rvvM+//oZdMz1ooJ3dO+tEK1f7n/56H5V5rWdo866jkqQ4tmL733Nat5lce4v0a29YXokGAAAAAMBEEw0AAAAAgIkmGgAAAAAAE000AAAAAAAmmmgAAAAAAEw00QAAAAAAmGiiAQAAAAAw0UQDAAAAAGCiiQYAAAAAwEQTDQAAAACAKQohhFJP4o81NDSorq5OF+hyZaKy0kwilS58zTjv5aLIr1nqXWc+TztvONsuOfh/LfWCSbY9wf6Mpp3sDf/ci/745j5N19TYJfONjVYuM36sXTPevNXPtrTYWVd6wABvbHPbJSnkcnY2VVXljd/c7Nfs18+r2dRk17THNrdHkqJMxs66S0a8b59dM5XNejVbW+2aisyfEYfYiuVCuxaFh1RfX6/a2lp/HjisA+v9hRV/qUxU3v1/kPau5ZGZk6Son3+euPI7dlq5VP86u2bY719zQ1u7lYvK/PM+VeutT01/NsauWfX7t7yguT2SFGWN4+i/tU8YYeXSK173x6+s8IKDvPVOkrS3wYrFo4faJdO7Eqyj5vhKJbh/HTrIikWN/nobEqw5GjzQy+3c7dcc4m1T2OTfa4W2NiuXGjfaruleR9+egHmvvXuvXTIyryWhyd/3Ucpb70N799eSXNymx3bdba31vBINAAAAAICJJhoAAAAAABNNNAAAAAAAJppoAAAAAABMNNEAAAAAAJhoogEAAAAAMNFEAwAAAABgookGAAAAAMBEEw0AAAAAgClT6gm8Y6LIjrZdfIaVK3/kuSOdzWFFmTI7G3LtfuEQrFh6yBC7ZLy33soN/t4Su2ZRxHk7GrXlrJz3bL4tXVdr5fLm85lE7o03C15Tkn8+mcedJOX37DnCyXQhwXkfNzdbuW1/O9OuOezbpTv23e1JrAj7PuTjgtdMVVVYuai83By6TSrCIQop5PIKUffX3lS/KqteVOavo01njLZy2V88b9d01/Gotsavmc3a2ZDz1rF4lL/eh3rvelL19Gq7psq8W9Ak17Korc3O5rNpK5cx5ylJ4bihVi5at8muqbQ3z9SaDXbJuM2/f0wN6G/lQoKa8Zq3vLH719k1o8pKOxt27rZy9RefZNfs/+SbXrDSW5skKSr3riX5N9bbNdPV/fzxa6q98Rv3+eOb172QoKbGe9fxUNb9uRTyrdIub1heiQYAAAAAwEQTDQAAAACAiSYaAAAAAAATTTQAAAAAACaaaAAAAAAATDTRAAAAAACYaKIBAAAAADDRRAMAAAAAYKKJBgAAAADARBMNAAAAAIApCiGEUk/ijzU0NKiurk4rXx6qmprue/wbxpxb+ElEkZcr9VPnzlMq/VyBQkml/WycL948SiRVU2Pl4sbGIk3AfP772HOfC+1apIdVX1+v2traUk+nTziw3n9n2ZmqrM50m7/3pNFW3SjtXyPCmSdbufS6rX7N5v1WLlXdz67ZfvxwOxs984KXS/I85XJWLjN6lF0zv8V7TqPycrtm3NJqZ1P9qrzxqyrtmvkdu7xgkuujec1NVWTtkom2afdeLxhiu2a6zruGtpx9gl0z+/QrdjaqrPCCbe12zbjVO/aiTPfXugN2XzXFyg362at2zbi52c7mZp5i5dKLlts13etOethQu2Z+p3feBWMfJVnreSUaAAAAAABTwZvoW2+9VVEUdfqaPHlyoYcBAAAlwloPADiW+b9TkMApp5yi3/zmN38YJMGvLgAAgJ6PtR4AcKwqyoqXyWQ0fLj/9zsAAKB3Ya0HAByrivI30a+//rpGjhyp448/Xh/60Ie0fv36w2ZbW1vV0NDQ6QsAAPRsSdZ6ifUeANB3FLyJnj59uu655x498sgjuuuuu7Ru3Tqdd955ajzMO8UuWLBAdXV1HV+jR3vvvgkAAEoj6Vovsd4DAPqOgjfRc+bM0Qc+8AFNmTJFs2fP1i9+8Qvt3btXP/nJTw6Znz9/vurr6zu+NmzYUOgpAQCAAkq61kus9wCAvqPo7wLSv39/nXjiiVqzZs0hv5/NZpXN+p9tBwAAepbu1nqJ9R4A0HcU/XOi9+3bp7Vr12rEiBHFHgoAAJQAaz0A4FhS8Fei/+7v/k6XXXaZxo4dq82bN+tLX/qS0um0rrnmmkR1/vbkGcpEZQWb10dfW2dnv3/i+IKN2yGKvFwIfslM4Z6fjuHb2wpeszeJzFdJQmtrkWeCw4nSaTsb4rydTfXrZ+Xipia7ps29PkiKu/ib03dEgue04BI8T4rMnxGXcnt6sUKt9ZL00z8/Q5lUebe5zCjvluXVm0fZY5/49yu8YHn38zsgNXiglcu9tdGvOXKQnY2mnuTlNu2wa8Z79ni5XbvtmiH27neiBOd9ql+VP/6JY7zx12+3a6arvXUkX4TreFTu3xOG5v12NjN6pBdsTXD/aO7T7PZmu2SS+7L86SdYubL1O+2aKXOfRv3r7JoD/+MFKxe3+c99erB/LUm9+JYXHDzYrpnfYV53yvwWNXW8dy6HtzZ1Xyu0SeZhV/AmeuPGjbrmmmu0a9cuDRkyROeee66WLl2qIUOGFHooAABQAqz1AIBjWcGb6Pvvv7/QJQEAQA/CWg8AOJYV/W+iAQAAAADoK2iiAQAAAAAw0UQDAAAAAGCiiQYAAAAAwEQTDQAAAACAiSYaAAAAAAATTTQAAAAAACaaaAAAAAAATJlST+BoRRlvE/73DVfaNVNabg4e2TUzI0dYudymzXbN0N5mZ5vfP93K1Tz1hl0z3ltv5ZLMsxjSJ06ws/nX/e23mcdJlE7bJUMud6SzKYiorNzLlZfZNeOmJitXrOPJHT/Jea8QvJIZ/3kKufaCjv32BAq/TZkRw+2SuS1b/fFN6drqgtYLoU3aW9CS+G+hrU3B+JG+u96P/5l/jXCvpVF1P7tmvr937EWb/Vuw1NqNdnb/9BOsXEUYbNdM96u0cvlN/rmc6ldl5dz9Lkn5SaPtbObNbVYu0ZqTzXpj19XaJUNjo5drM9cGJXtO3fUh1NXYJcNm77nXnr12zch87iUp86J3rxcS3MMoMl+XTLDepmq95zRu3GfXDAnuDfK791q5aOpku2bk9g77W+yaqqrwxh43qvtMvlV61RuWV6IBAAAAADDRRAMAAAAAYKKJBgAAAADARBMNAAAAAICJJhoAAAAAABNNNAAAAAAAJppoAAAAAABMNNEAAAAAAJhoogEAAAAAMNFEAwAAAABgypR6Akcr5HJWLrV4eREGD3Y0t2lz4cdPoOrBZ61cvghjR2Xldjbk2s2g/9znX1trZ4vCnOtkbxdJkl67ZIiVy+/a7ReN/b0f2tsKmutVEhx7dskiPE/pUybZ2fxLqws+fm7L1oLXTHTe760v6ND5YF6bkFjc1Kw46v75TbV7633mSf/YS1VVWbmoosKuGVa8bOXSgwbaNeMEx3PF4lVeMJXgdZS6Wi93un/difY2ebkW//qYXufve3d9jLJZu2Zk5l659Xi75phfxFaucuM+u2Z4/S07625T1OCPH9XWWLnQvN+uqbx/DxMN7O+V3Ojfu6dqvG2Kt+2wa8b7ve3f++Fz7JqDfuZdnyQpSqetXGqzv03qX2fFQmOC43n3XisXpbu/5oXgX294JRoAAAAAABNNNAAAAAAAJppoAAAAAABMNNEAAAAAAJhoogEAAAAAMNFEAwAAAABgookGAAAAAMBEEw0AAAAAgIkmGgAAAAAAU6bUEzicDZ+frnRFRbe5Mbc9U/CxU/36Wbm4udkvGsIRzqb3C+1tpZ5Cr/DKtFyC9I6izaNPiSI/20vO0dcXTrdyJ8x9tsgzAQrjjS9OUcpY7yd8xjumU9msPfb+mZOsXOWGBrumNpuvT+T8a35q3Gg7G7+5wcqlhwy2a+a2bLVymcru9+MB8Y5dVi4aPNCumd/k1ZSkKJ32ggnWhtDu7dMT562wa6YHDvCCKf91sVxLq52Ndu+1cvnGRrtmqqrKzrqi44b74VzeiqUG+cde2Nfkj296/c6zrdzkb3nnZ1JRmdcm5rf796T2vo9jv2ZdjVdyb323mRC8Y0PilWgAAAAAAGw00QAAAAAAmGiiAQAAAAAw0UQDAAAAAGCiiQYAAAAAwEQTDQAAAACAiSYaAAAAAAATTTQAAAAAACaaaAAAAAAATDTRAAAAAACYMqWewOGM+7e1yqTKu83lizB2NGaklUtt3GrXjBsbrVxm9Ci7Zm7DRjtriyI/G4IVS08c79es32fF8jt3+jXNeSYRZfxTJ+RyBR+/T3KPvQT7M1VZaWfj5mY7ayvCNh3/QLs3dDZr1wytrXY2VVFh5eKWFrtm2+wzrVz5o8/bNYvx3KM4Jvy4UZl0W7e5kE5b9eI27xyRpLJGM5vouuOdI/kTx9g102s32Vlbkm3q18/KtQ+v82vWeTW1xV/v09VmTUnB3P7UoAF+zab9XjDBehPva7JykXltlpI9T/F+71oelXd/z96RraqycqHJ2/a3i/r3r2H3Hi+Y4F4vMp/T0Ojd50rSuIfN+8ck9+4JRKNGeLl1G+yaLeeeZOUqf7fWrmnfkztrSIgl82nnlWgAAAAAAEyJm+gnnnhCl112mUaOHKkoivTQQw91+n4IQV/84hc1YsQIVVZWatasWXr99dcLNV8AAFBkrPUAABxe4ia6qalJU6dO1cKFCw/5/dtvv1133nmnvvvd7+rZZ59Vv379NHv2bLUk+NU+AABQOqz1AAAcXuK/iZ4zZ47mzJlzyO+FEPTNb35Tt9xyiy6//HJJ0r//+79r2LBheuihh3T11Vcf3WwBAEDRsdYDAHB4Bf2b6HXr1mnr1q2aNWtWx2N1dXWaPn26lixZcsj/prW1VQ0NDZ2+AABAz3Qka73Eeg8A6DsK2kRv3fr2u1UPGzas0+PDhg3r+N6fWrBggerq6jq+Ro8eXcgpAQCAAjqStV5ivQcA9B0lf3fu+fPnq76+vuNrwwb/bdIBAEDvwHoPAOgrCtpEDx8+XJK0bdu2To9v27at43t/KpvNqra2ttMXAADomY5krZdY7wEAfUdBm+jx48dr+PDheuyxxzoea2ho0LPPPqsZM2YUcigAAFACrPUAgGNd4nfn3rdvn9asWdPx73Xr1mnFihUaOHCgxowZo0996lP66le/qhNOOEHjx4/XF77wBY0cOVJXXHFFonHyO3cqisq6ze36G2/BHvT9pf7Yr5Tusy5zGzYWpW77xWdaubJfPV/wsfNr1hW8ZqlF2aydDfm8GQxHOJt3XmrqSVYu2rrLrpnftt3KpU86wa+Z4FzOHD/OyuXeeNOuae/TVNoumV70e29ou2IycRE+wqj80cJfd3rT+dQTvVNrvSTFq15XbKz3O//mbKve8F/6vyYer/CuEXFrq13TlXrlTT9cVWlH937QW+8HPprgXiflveaSNp9PSYr69bNyITbXUEnxfv/6FHLtXs2Txtk1M1tiL5jL2TWVNl/vCubYkvKNjXa2+QrvvCuv97cp+4J3X9j03lPtmlW/WGFnW9471cpVLnrJrune66XGjrJrlv1mmTd2VZVdM7S12dlU2rs3SVV757Iklf+q8NuUry/cm1SG4B/HiZvo559/Xu95z3s6/j1v3jxJ0nXXXad77rlHn/3sZ9XU1KSPfexj2rt3r84991w98sgjqqioSDoUAAAoAdZ6AAAOL3ETfcEFFyh08RP+KIr05S9/WV/+8pePamIAAKA0WOsBADi8kr87NwAAAAAAvQVNNAAAAAAAJppoAAAAAABMNNEAAAAAAJhoogEAAAAAMNFEAwAAAABgookGAAAAAMBEEw0AAAAAgClT6gkcTuq0SUqls93mBn1/qVcwhKOc0Tsjyvi7JORydrbsV88fyXS6lB48yMrld+4q+NhJRGXldjbk2q1c3NR0pNPpsXb+7EQ7O/iyV4o4k67lX3m9KHVzb7xZlLoonPSwoXY2v227V7O21sqF0CY12MMjgeb3/ZkyZRXd5ob/coNVL7S02mPb62jkv+aQqu7nBUcMsWtq8zY7Wnffs1YuSnA+tZ021sqVPe9fn+M9e6xcyOftmqnTJtnZdON+b/xX37Jr5ve3WDn7GEkgbtxnZzf8/Qw7O27hS14wwTninnfVj79q14xTkZ2teGylF0xwT+7eE4cE/UiqovvropSsd4hqqu2sWr1raWTOU5KidNrKtU2fbNcse/JFKxefdVK3mZBrkbxLKK9EAwAAAADgookGAAAAAMBEEw0AAAAAgIkmGgAAAAAAE000AAAAAAAmmmgAAAAAAEw00QAAAAAAmGiiAQAAAAAw0UQDAAAAAGDKlHoCh3Px959VRXX30/v5KQPegdm8c0IcSj0FW37nLiuXqqmxa8aNjUc6ncMK7W0Fr5mqqLCzcUtLwccvhuGfaLazuSLO45gU50s9A18UeblQ+GtZvHtvwWvmGxq8XGgv+Nh4294PNild1f1VperBTV7ByH99IDNsiJULbf46EpnrQ76q3K6p/QnWEfPcCzn/Sl727KtWrvnCU+2a/Z7wasYJtj21Y6+djfd42dZzT7Frli96wcrl9+yxa0Zl3nES8v46UrPBvz7n671rZCqbtWtGlZVersrLSVJ6YH87m1tvXksSPKfx3norFyU471whwXobdu22s6kTxlu53Oo37Jrp6n7e2O2xXTNKe9f81O9e6j6TYK3nlWgAAAAAAEw00QAAAAAAmGiiAQAAAAAw0UQDAAAAAGCiiQYAAAAAwEQTDQAAAACAiSYaAAAAAAATTTQAAAAAACaaaAAAAAAATDTRAAAAAACYMqWewOE8cnZ/ZaKygtWLysrtbGhvK9i4icX50o1dJHFjY6mnUHBxS0vhi0aRH02nrVzI5eyauQ0b7SyOYSGUbugiXJv/c+NSK9fQGGv05IIPD0mjb9qiTGSs0TU1Vr3m8yb5g//ieSuWHjjALhna2r3cspfsmkmk+9d5wUH+NqnVO/eqfrPSLhnnYyuXcrdHUoi9mpIUm/upfPGLds2ostIbe8oEu2ZbtXernv2t/9wPfuwtOxv697dyUf9au2a8faeVy+/da9eMTj/Zzmq9H7W5a2Pev893j9FUyn9NNDXAP+/zr7xu5dIJasb7mqxc5vev2TVV5vWLV694o9vM/n05PT7NG5ZXogEAAAAAMNFEAwAAAABgookGAAAAAMBEEw0AAAAAgIkmGgAAAAAAE000AAAAAAAmmmgAAAAAAEw00QAAAAAAmGiiAQAAAAAw0UQDAAAAAGDKlHoC75TQ3lbqKaAX+MWm31u5S487o/CDh+BHc7nCjw/0IVE2a+WuGnWOlcuFdkkPH8WMcDihrU0hcnLtVr2qpWv9sc3jJLS02jWj6n5WLlVZaddM1dbY2fzOXVYuysf++HW1Vi7es9euKXP8/M6ddsnUKZPs7Ld/96CV+9sTL7RrKp+3YtGSF+2S5bFZs8Y/RpLcQ8SNjV5wX5NdM9XPO/ajdNquGVa8bGfT5vEcDejvj1/mtVTxug12zfTEcV7NN96ya0ajR9rZTIV5fWxu9sc3n6fU4IF2zT0zjrNyPz6r+0wutEn6nVWPV6IBAAAAADAlbqKfeOIJXXbZZRo5cqSiKNJDDz3U6fvXX3+9oijq9HXJJZcUar4AAKDIWOsBADi8xE10U1OTpk6dqoULFx42c8kll2jLli0dXz/60Y+OapIAAOCdw1oPAMDhJf6b6Dlz5mjOnDldZrLZrIYPH27Va21tVWvrH/7WqKGhIemUAABAARV6rZdY7wEAfUdR/iZ60aJFGjp0qCZNmqSPf/zj2rXr8G9ysWDBAtXV1XV8jR49uhhTAgAABZRkrZdY7wEAfUfBm+hLLrlE//7v/67HHntM//zP/6zFixdrzpw5yh/mHQvnz5+v+vr6jq8NG/x3rQMAAO+8pGu9xHoPAOg7Cv4RV1dffXXH/z/ttNM0ZcoUTZgwQYsWLdJFF110UD6bzSprfsQEAAAovaRrvcR6DwDoO4r+EVfHH3+8Bg8erDVr1hR7KAAAUAKs9QCAY0nRm+iNGzdq165dGjFiRLGHAgAAJcBaDwA4liT+de59+/Z1+knzunXrtGLFCg0cOFADBw7UbbfdpquuukrDhw/X2rVr9dnPflYTJ07U7NmzE41z2lNStrr73Ippaa9gfPi/0+pJogS/6hb+6F1OCzeByM+GULqaRXLpcWdYuais3K4Z2tuOdDqHlyr8cZ+urbWz+WK8q657nJT4GCmGVEWFnY1bWsyi5jEi9ZrrY3rIEDub37GjiDPp+96ptV6S1t90mtLZ7s+Bcfdv9Qru3JN4Dt2JyvzbpdC4zwueMNavud7cdkkh9q6R6f51dk3lclYsNXigXTLeudsLpvx7iFSCff+3E97t1TzR30/x2resXHpgf7tmVFvjjb2j6zf2+2P58f676mfctTnJvV7GO5/SlZV2yXhfU8HHz2/cYpdM1RpNi6TolIl2zfzK1VYuPXGcXVNbttvRUGnem3TxXhh/Km7xepfcuMF2zZqfPGflImMfRcF/fTlxE/3888/rPe95T8e/582bJ0m67rrrdNddd2nlypX6wQ9+oL1792rkyJG6+OKL9ZWvfIW/gwIAoJdgrQcA4PASN9EXXHCBQhevBD366KNHNSEAAFBarPUAABxe0f8mGgAAAACAvoImGgAAAAAAE000AAAAAAAmmmgAAAAAAEw00QAAAAAAmGiiAQAAAAAw0UQDAAAAAGCiiQYAAAAAwJQp9QQO5+X31SoTlXcfjOu9glHkDx6Cny2w0NpasrHfnkCCbXef0xI+n5KKsu9De9sRTqYL50yxo02jKq1cv/941h8/m/Wzxdj3xThOesl5H7e0FLxmlPK3PSjtF47z5gQK/9znd+zwa5o2zp/pjd3aIv3LwwUfH9Ko3zQqk2nvPrjHW++j2mp77Li52auZSXC71GZsi6Ro3Sa7ZGjz1xz33A8t/v1GVF7m1dzXZNcMuZyVSyVZm9L+tSxVVWXl4tfftGtGae+1qaYZE+ya7f28mv1/3WDXDAnWB5UVft8r7PdiCY7R1OBBdjbevcfKufvz7Ql4x15q6y6/Zj/vGE1kaILn6c0NVi49ZLBdM2VeHzOvbbFrxub1aftVJ3ebybe1SP/ujcsr0QAAAAAAmGiiAQAAAAAw0UQDAAAAAGCiiQYAAAAAwEQTDQAAAACAiSYaAAAAAAATTTQAAAAAACaaaAAAAAAATDTRAAAAAACYMqWewOHE+1sVR3HhCobgZ6PIiqUHDbRL5nfuKujYiSXZ/gLXjP7sFL/kipcLOnbibCrt5eK8X9Pdp8++aJfst9TbpvSJE+ya+dfW2tliyIweZeVyGzb6RRPs+/wFZ1i59KLf2zXTgwd5Y7vXB8k+nlIDBvg1B9b5w7fnrFzujTf98Yt13TOMWvCMlcuFdr1e5LkcqzK79ymTau82l2/cZ9WLWtvssVP9vWM/jBhs14xXrrZy6SHVds1UVaWdzW3bbmdd8Z69Vq797Ml2zezqzd7YDY12zWDOU5JSA/pbuSjvr/dRVZWVq37uLbumu/25PzvRrple/po/vnl9Dq2tdk392UlezWXmPaEk7d5jR1tneuNXLF9n1wzHDbFy8Utr7JrpwV6fke9XYdeMq8rsrIbUernfv2qXdO+LQlv3a8IB7rk89IGXus3kQoL1w04CAAAAAHCMo4kGAAAAAMBEEw0AAAAAgIkmGgAAAAAAE000AAAAAAAmmmgAAAAAAEw00QAAAAAAmGiiAQAAAAAw0UQDAAAAAGCiiQYAAAAAwJQp9QQOJ7S2KkRxiQYPViy/c5ddsm32mVau/NHn7Zq9RVj+UsFrRhn/0A25nF84zh/BbLqbgHc8JdmmVHU/K5d/ba1dMyort7Ohvc3OunIbNha8ps4+zY6mF/2+4MMnuUbY3OvTjh1+zSTZIsgMH2blclu2FnzsN786w8rFLS3SVx4u+PiQ8hu3KorKus2lhw2x6oWGRnvseNduK5dKsI7UX3uWlRvw4It2zfz+FjubGTnCyrnbLkmpQQO9sZ9eZdcMA/tbuWjcKLumNvnXiNyWbVYuVVnhj2/eQ4Sh3vMpSbmJ3v5MP/eKXVOTj/ezq9d54w8ZbJeMX33TC6Yiu2bD+6bY2eoHnrVycab769IB0atvWLlUv0q7Zmhq9mqu9XKSFJn3EJKkvHc8pwb0t0vuP2Wklcs+4V9L4rzXL265qfteLN/aIi30xuWVaAAAAAAATDTRAAAAAACYaKIBAAAAADDRRAMAAAAAYKKJBgAAAADARBMNAAAAAICJJhoAAAAAABNNNAAAAAAAJppoAAAAAABMmVJP4LBSaSlKdxtLTzreKhevecseOrS32VlX+aPPF7xmIqnun0tJSlVk7ZJxc/ORzuaohXy+ZGNLkqLIz4ZgxVI1NXbJV/7pBCt34sd/Z9dMctxnRgy3cvGevXbNuKXFzrpSK1/3xy/46L50/zo7m99bX8SZlEZuy9aSjT3hW2usXC5u0xtFnsuxKj1ssNKp7tee1olDrXrlG/11LNrkHXthv399GvDwS97Y1f3smum0t4ZLkjJeNpow1i4Zdu7xaqYTvDbT1u7V3O1f82KzpiQpeFf91ID+fslWbx2Ny/3b770nVlq5wS+U2zWj9f41N/dnk7yaexPcE+5rsmKpBOdI3ard/vjm/VYx7jXj8aP88CrvHiZVW+3XbGm1o+72u8e9JGWfWGXlokrvuJekuL7Byo14qrHbTC7folfMcXklGgAAAAAAU6ImesGCBTrrrLNUU1OjoUOH6oorrtDq1as7ZVpaWjR37lwNGjRI1dXVuuqqq7Rt27aCThoAABQHaz0AAF1L1EQvXrxYc+fO1dKlS/XrX/9a7e3tuvjii9XU9Idfy7j55pv1s5/9TA888IAWL16szZs368orryz4xAEAQOGx1gMA0LVEfxP9yCOPdPr3Pffco6FDh2rZsmU6//zzVV9fr+9///u67777dOGFF0qS7r77bp100klaunSpzjnnnMLNHAAAFBxrPQAAXTuqv4mur3/7zR4GDhwoSVq2bJna29s1a9asjszkyZM1ZswYLVmy5JA1Wltb1dDQ0OkLAAD0DIVY6yXWewBA33HETXQcx/rUpz6ld73rXTr11FMlSVu3blV5ebn69+/fKTts2DBt3XrodwJcsGCB6urqOr5Gjx59pFMCAAAFVKi1XmK9BwD0HUfcRM+dO1erVq3S/ffff1QTmD9/vurr6zu+NmzYcFT1AABAYRRqrZdY7wEAfccRfU70TTfdpJ///Od64oknNGrUHz7vbPjw4Wpra9PevXs7/YR627ZtGj780J8rm81mlc36n+kIAACKr5BrvcR6DwDoOxK9Eh1C0E033aQHH3xQv/3tbzV+/PhO3582bZrKysr02GOPdTy2evVqrV+/XjNmzCjMjAEAQNGw1gMA0LVEr0TPnTtX9913nx5++GHV1NR0/O1TXV2dKisrVVdXp49+9KOaN2+eBg4cqNraWn3yk5/UjBkzeLdOAAB6AdZ6AAC6FoUQgh2OokM+fvfdd+v666+XJLW0tOjTn/60fvSjH6m1tVWzZ8/Wd77znS5/xeuPNTQ0qK6uThfocmWiMndqPd6jm1dYudkjTy/qPNCNVNrLxfnizgNAj5IL7Vqkh1VfX6/a2tpST6eo3om1XvrDen9h1dXKROWFmLokKUwa333ov0Vr1lu5eN8+u+ajm5Zbudmjptk1MyOG2VmlvF8yzG85/JvA/akQm7eKIbZruqLyBMdG3l+b9885w8pV/fYlu2bI5bxca6tdU4c5H49GaspkOxu/+JpXs9y/Z3efp2jyRLtmtHWHnc3v2m3l0iedYNeMX3vDyqXq/PUjHjPCyoXl/jEaJfiTmtTokVYu3rDZrmmPnWCe0aABXjDu/vqUi1v1m/Xfsdb6RK9EO/12RUWFFi5cqIULFyYpDQAAegDWegAAunZUnxMNAAAAAMCxhCYaAAAAAAATTTQAAAAAACaaaAAAAAAATDTRAAAAAACYaKIBAAAAADDRRAMAAAAAYKKJBgAAAADARBMNAAAAAIApU+oJHE6UySiKup9eyOWsepkRw+2xc1u3WblUdbVdc/bI0+1sKWVGj7KzuQ0brVy6f51dM1/fYOVSVVV2zbipyc4qxH7W5M413r/frhml01Yu5PN2TYXgZ11RlCBr/kwv9rep/eIz7WzZr5d5QXeeSSTYJqW8fZ+kZqqiws7GLS121hWVlVu50N5m10yffKKVaxlVa+VyuRbpsYft8eFLDRygVCrbbS7esdOqFyW47kVVlVYuPXyIXfPS0wZYuVR5s10z3ltvZ6Ny73yKTvXOEUmKXn3Dy4317yG029ymOv9eSzt329F+v3vTC5rPpySlhnnHSWj070uiiu7PDUkKLa12Ta3fakfTtebzn/FbilRZmZXLv77Orpk752Q7W7bKu9+J9nj3pJKUHjzIyoUEa2h66y6vZoL77Gigd32SpLDdG9+9J5Wk1KCB3tiNjXbN/GBvHc9XdX+M5nIt0npvXF6JBgAAAADARBMNAAAAAICJJhoAAAAAABNNNAAAAAAAJppoAAAAAABMNNEAAAAAAJhoogEAAAAAMNFEAwAAAABgookGAAAAAMCUKfUEDifkcgpR1G1u2ydnWvWGffuZo53SQeLGxoLXlLHNB6z54el2duKHl1u53IaNdk1Xfm99wWvGTU0FrylJCqHgJePm5oLXDLlcwWsmkkp7uTjv1wxeNiort0uW/ep5f3xb7Efd4ynBeZ/oOXVLtrTY2SibtXKhtdWuGdrb7Kwr//JrVq7sZa9eFNqPYjboSmhrV0h1fw689k+nW/Umf2uTP7aZy7/+hl3TPUeikybYNVfPq7Czk/92rTf+hq12zZDyXnPJr15j17Svezt2+DUTcNeS9Mhhds14s/ecJrrmZsxb9SjB62IhwTo2dZI3/EvecSdJ+Tbvepo/f6pdM73Yu8+VpGjsaG/8ATV2Tb3sHftJzvvw2ptWLtF9ZsM+O5p7z+lWrmzxC35Ns89IDxhg1wzPvejVNM75kGCt55VoAAAAAABMNNEAAAAAAJhoogEAAAAAMNFEAwAAAABgookGAAAAAMBEEw0AAAAAgIkmGgAAAAAAE000AAAAAAAmmmgAAAAAAEw00QAAAAAAmKIQQij1JP5YQ0OD6urqdIEuVyYqK/V0uhZFfrZnPc0FEZ97upVLPf2CXTNdU2Pl8g0Nds3dPz/Rzg5832t2ttBS5rZLUtzYWMSZFFAq7WfjfPHmUSruNaIY14cSX5+isnJ/+Ly57xMcI1Em442dy1m5XGjXIj2s+vp61dbW2vPA4R1Y79+Tucpa76Ns1qrr7lNJUuwd++njhtslQ+M+L5jgHI331ttZdy2JqirtmvXnjLZydcu22DVzQ+usXGrVWrvmxrmn29kx/98bXjDJ9dHcp/lRQ/yaK737klRVlV8zgbB/v5WLRo+0a0bNLVYut2WbXzPt329EFea1pK3NrpkeMczKxdt32jXd8dPHjfBrNjX72WZz348bZddUu3d9jhqb7JKhpp+X27qj20wutOm3jfdaaz2vRAMAAAAAYKKJBgAAAADARBMNAAAAAICJJhoAAAAAABNNNAAAAAAAJppoAAAAAABMNNEAAAAAAJhoogEAAAAAMNFEAwAAAABgypR6AkctirxcCHbJVFWVlYubm+2arvTgQXY2v2u3X3fggILXLF+zxcrlEjz3YcxIL7iqwa458H2v2dlicI+n4gye9rNxvvDjF6NmiaUqKuxs3NJS+PH79fPGbmoq+NiS7GtuyLXbJV//1tlW7oS/fdauGXI5O4vSCrmcgnFcpYcNterltmyzx06dfIKVi9e8addUynt9IpwywS6Z3lhmZ/PHDbZy0Svr7Jr9Nnk18wme+9yEIVYuW+lfc0f/75fsbMiYt8Bt/rVMo0dYsagtwfXJnGdU7a0NkpTb5N2/SVJ6iHlfum2nXTNua7NyqQT7Psl9flRV6eVGDfeH3+HdP4e8f18UTZ7o1dyy3a4ZWlrtbKq2xgvu8e/Jt88Zb+UG/ftzds2Uue+dbQ/BP995JRoAAAAAAFOiJnrBggU666yzVFNTo6FDh+qKK67Q6tWrO2UuuOACRVHU6evGG28s6KQBAEBxsNYDANC1RE304sWLNXfuXC1dulS//vWv1d7erosvvlhNf/JrgzfccIO2bNnS8XX77bcXdNIAAKA4WOsBAOhaor+JfuSRRzr9+5577tHQoUO1bNkynX/++R2PV1VVafhw/+8IAABAz8BaDwBA147qb6Lr6+slSQMHDuz0+L333qvBgwfr1FNP1fz589XcxRtwtba2qqGhodMXAADoGQqx1kus9wCAvuOI3507jmN96lOf0rve9S6deuqpHY9fe+21Gjt2rEaOHKmVK1fqc5/7nFavXq2f/vSnh6yzYMEC3XbbbUc6DQAAUCSFWusl1nsAQN9xxE303LlztWrVKj311FOdHv/Yxz7W8f9PO+00jRgxQhdddJHWrl2rCRMO/jiH+fPna968eR3/bmho0OjRo490WgAAoEAKtdZLrPcAgL7jiJrom266ST//+c/1xBNPaNSoUV1mp0+fLklas2bNIRfWbDarbDZ7JNMAAABFUsi1XmK9BwD0HYma6BCCPvnJT+rBBx/UokWLNH589x+YvWLFCknSiBHeB9ADAIDSYa0HAKBriZrouXPn6r777tPDDz+smpoabd26VZJUV1enyspKrV27Vvfdd58uvfRSDRo0SCtXrtTNN9+s888/X1OmTCnKBgAAgMJhrQcAoGtRCCHY4Sg65ON33323rr/+em3YsEEf/vCHtWrVKjU1NWn06NF6//vfr1tuuUW1tbXWGA0NDaqrq9MFulyZqKzbfHpi9z8hl6QoH1s5Scqte8vOAoUSlZX74eAdzyGXO8LZdM2da2hvK8r4QKFMeK7CyrXta9PdF/xE9fX19nrWW70Ta730h/X+wqqrlYm6v6bsvHqqN39/udeAHyz1gpH/YSbp6n5WLu7m3cw7DZ/g1+BTtTVe0L/9k8q6vx+TpNzGTX5N8zmN0mm/ZJn/2lBoK/z65O6n3J+dYNdM5bwDOrXiNbtm1K/KzrafPNbKlb+5w66Z3+5lQ7t/D5OqSPCnIrF5kUgl+BCjw1w3Dyo5ZJBdMr9xsxdMcI6k+tf54+/YZeUyo0faNXPrN1q5VJV/jMb7W6zcuvtO6b5Wc4vW/dU/WWt94l/n7sro0aO1ePHiJCUBAEAPwloPAEDXjupzogEAAAAAOJbQRAMAAAAAYKKJBgAAAADARBMNAAAAAICJJhoAAAAAABNNNAAAAAAAJppoAAAAAABMNNEAAAAAAJhoogEAAAAAMGVKPYGjVuZtQrxxg18zirxcCH5NVyrtZ0OcIOvNNcr4h0TI5ws6dp9lHk+pgf3tkhuum2jlRt6xxK6ZZD/lzznFyqWXvOgPn8tZuUTHaFyEY68I512qosIuGbe0+OOjW2/9P/2tXC5uK+5EjmFRZaWiVHm3uQGr91v1Mtsb/LGHDbVy+T177Zrxfu8cTY8YbteUeX2UpNDebuWi6n7++K3e8Z+uqbFLhmLcl+z3jpEkdaPKSr9mtvvjWJLSTd4+kqR9x1dbubo36+ya7jEiSXG5+Xpbyrx3lpTKZq1cNNw7PyVJSdZ789hL8jy552gw+xZJUuQ996mqKr9mgmtJutY79kK9f81NmedTVO6dS5IUtXn76fg7uu9bcvlY68xxeSUaAAAAAAATTTQAAAAAACaaaAAAAAAATDTRAAAAAACYaKIBAAAAADDRRAMAAAAAYKKJBgAAAADARBMNAAAAAICJJhoAAAAAAFOm1BM4nNSpJyqVznaby698tfBjV1VZubi5OUHRtBWLyvxdkh453M7m1r1l5UIuZ9e0RZGfDaHw4yeQHjDAC6b8bcrv2u3ltm23a4683c/azGNUklJPLrdyxdibG//ubDt73Nee8Qubx2mU9p8n93xKdN65+ynO+zUTyIwfa+Xca04S6UED7Wx+9x4rl9uy1cuFdntsJNN28mjFmYpuc+Ur1hZ87DBiqJWLGvfZNVODveM0lJfZNXNDBtnZ9Itv2Flbm3n8V3a/HzuYz2nc1maXTNVU29kwapiXsytK4XXzXivBet/vBe/1rjjBc+8eo5JUvtS7zw4J1kaZ2T3nHGeXrH3Iuy+RpPRA714vSvCcBvN4jnL+2pwe7l2f4h077Zrucy9J+akTvZIJrjkhb27/2BF2zdQWb/vzy7s/lkOCtZ5XogEAAAAAMNFEAwAAAABgookGAAAAAMBEEw0AAAAAgIkmGgAAAAAAE000AAAAAAAmmmgAAAAAAEw00QAAAAAAmGiiAQAAAAAw0UQDAAAAAGDKlHoChxOvek1xVFaasZubi1A0b8VCq5eTpNy6t450Nu+sEEo6fHrQQDt749KlVm7hCSce6XR6LvMYLbXjvvZMcQqbx2nI5fyaUVT4miVWyutOfk+9nU0PHuzV3LHjSKeDAsm+tkWZVHm3ufy+JqteqqbGHjts3GrlovLu53dAvGOXVzPj34Jldu/1x29ptXKp6n52TZnZUJbgtrJxn1ezrc0vef5EO7vjau9e7/j/sdGu6d7tRBn//ja0e9sfJXjug3mMSP76FKXTdk2Zx37/X75sl8wnOE5kzjXsb/FrDhpgxeJN3jUnkQTPfWpAfzsbrd7gBasq7ZrusRfM+ydJajxvvJWrfnhvt5koxFLsjcsr0QAAAAAAmGiiAQAAAAAw0UQDAAAAAGCiiQYAAAAAwEQTDQAAAACAiSYaAAAAAAATTTQAAAAAACaaaAAAAAAATDTRAAAAAACYMqWewOGs+cY0pSorus2d+InfWfUyI4bbY+d37vaCIbZrhlzOzpZSZuxoO5t7a4OVSw8eZNfM79zlBaPIr7nL3J+SvnPqaWay1a5ZFO72h9A3xzdFZeV2NuTzZtA/7+3tT3A8KzJ/9hmb2yNJqbSfTVK30JI89/1rvJx7fQixlGB4+Ha9Z5zS5d2v9wN+5K0P8cRR9tjpnQ1eMMG1LN7S7JV0rzmSUtmsnY3Ky6xc+7hh/vjPveQFT5tk14xi74RKDx1i16x5/DU/u2qgF0ywn6Jyf81xpQd78wy5BNfmVv8eJtW/zgvub/HHd9cR81iWpMz4sf745j6N5I8f9njXklRNtV1TZd74YV+TXzPtv34am3WjJPcwKS+b3rLTLlnZz3ue0sO6v5aEuFXa5I3LK9EAAAAAAJgSNdF33XWXpkyZotraWtXW1mrGjBn65S9/2fH9lpYWzZ07V4MGDVJ1dbWuuuoqbdu2reCTBgAAxcFaDwBA1xI10aNGjdLXvvY1LVu2TM8//7wuvPBCXX755Xrppbd/zefmm2/Wz372Mz3wwANavHixNm/erCuvvLIoEwcAAIXHWg8AQNcS/U30ZZdd1unf//iP/6i77rpLS5cu1ahRo/T9739f9913ny688EJJ0t13362TTjpJS5cu1TnnnFO4WQMAgKJgrQcAoGtH/DfR+Xxe999/v5qamjRjxgwtW7ZM7e3tmjVrVkdm8uTJGjNmjJYsWXLYOq2trWpoaOj0BQAASq9Qa73Eeg8A6DsSN9Evvviiqqurlc1mdeONN+rBBx/UySefrK1bt6q8vFz9+/fvlB82bJi2bt162HoLFixQXV1dx9fo0f67QwMAgMIr9Fovsd4DAPqOxE30pEmTtGLFCj377LP6+Mc/ruuuu04vv/zyEU9g/vz5qq+v7/jasMH72CQAAFAchV7rJdZ7AEDfkfhzosvLyzVx4kRJ0rRp0/Tcc8/pW9/6lj74wQ+qra1Ne/fu7fQT6m3btmn48MN/RnM2m1U2wecfAgCA4ir0Wi+x3gMA+o6j/pzoOI7V2tqqadOmqaysTI899ljH91avXq3169drxowZRzsMAAAoEdZ6AAD+INEr0fPnz9ecOXM0ZswYNTY26r777tOiRYv06KOPqq6uTh/96Ec1b948DRw4ULW1tfrkJz+pGTNm8G6dAAD0Eqz1AAB0LVETvX37dn3kIx/Rli1bVFdXpylTpujRRx/Ve9/7XknSv/7rvyqVSumqq65Sa2urZs+ere985ztHNLGJ85YpE5Ud0X97KLktXb/hSbFFGe+pDrlcUcZPn3SClcu98nrBx87v3FXwmgqh8DUlhdbWotQtuCJtf68Z3xTa20o9BU+C5/Pjr622cnedMNEfP8772VJK8DzlX3+jwGP3kueoAN7JtV6SBvzfF5WJyrvNpYYPs+rllvl/ux0G1HnBvL//28891cpVrNlu11TsH/sb/spb70f9vyvsmlFNjZXLr/Cf+/S4MVYuVPp/AhDe2mRnY/MakR400K4p8x4uKu/+eD8gtHj3JfG+Jr9mguM5PSDt1Uxw/+rONVVZYddMsj7EDfu88Wur/Zr13qcNpMxzSZIG/tTb97sv83+xOLdhs52NUpGVSw0batdUmdcP5Tf680zv2Wvlcu3dH6O50G6Pm6iJ/v73v9/l9ysqKrRw4UItXLgwSVkAANBDsNYDANC1o/6baAAAAAAAjhU00QAAAAAAmGiiAQAAAAAw0UQDAAAAAGCiiQYAAAAAwEQTDQAAAACAiSYaAAAAAAATTTQAAAAAAKZMqSfQm4WZU+1sa/9yK5f9xXNHOp0u5V95vSh1SyXKZu1seshgOxv277dy+V277ZquKOOfjiGXK/j4OmeKn126svDjF0MU+dkQijePAvrf559r5aKyBMdoyn+eQmurlUv3r7Nrxk3eeRfa2+ya9vixt99DaJMa7OGRQJTNKoq6XyNzm7da9dK11fbYcb23U1tn/Zlfs8w7n3IbNts1kxi1cI+VC23++eSuT+mBA+ya8ZZt3thjjrNr5qdMtLOpNm8dzS9/1a4ZpdNWLn3ccLtm2N9i5VKVFXbN/TNOtLPZx1ZYuajcu8+VpPQA7/oc72uya6Yq+9vZsKfeG79hnz9+dT+vZnOzXXPHvElWLj3Qn2d68EA7m399nZWLh/S3a0ZN5vFcVWXXDMeP8sY27vNS+VbpRW9cXokGAAAAAMBEEw0AAAAAgIkmGgAAAAAAE000AAAAAAAmmmgAAAAAAEw00QAAAAAAmGiiAQAAAAAw0UQDAAAAAGCiiQYAAAAAwEQTDQAAAACAKQohhFJP4o81NDSorq5OF+hyZaKyUk8HQC+Wqqmxs3FjYxFngi5FkZcrwnL1k41LrFxDY6xxk7eovr5etbW1BZ/HsejAev+ezFXWep8ePMgrXFVpzyHeut3KhfacXTM9eKA3dn2DXTPk83Y2Ki+3cqnaBNfHPXutXGhrs2umqvt5wUzGrpnftdvOKvJeR0qV+/ei0dhRXnBngnkO7G/F4vWb7JLuMSJJco899zou2dfyuLnZLrnrhhl2dvDdz1m51IABds3Q0uIF29vtmlFF1srlG/bZNdMD6hKMX2Hlclu22TXDjNOsXOrZVXbNyLxGfP3Vx7vN7GuMNfNUb63nlWgAAAAAAEw00QAAAAAAmGiiAQAAAAAw0UQDAAAAAGCiiQYAAAAAwEQTDQAAAACAiSYaAAAAAAATTTQAAAAAACaaaAAAAAAATDTRAAAAAACYMqWewDslyvibGnK5Is6kgFJpPxvnizePvsR9TovxfEaRnw3BK9kXj/sE4sZGP2w+/1HaP+9C3jxOzP0pSY1Xn2Plau5fateMpp1iZ8Oyl+ysX9Tf/kI744GbrVzc0iLpluJO5hiVGjhAqVR5t7nQvN8rOKi/PXZUWeHlyv1rfn7HTrNm99t8QGrMcf74a9/yxk/7r6O417Ika07c5O3PqCzBrWrkb1N64jgrl3/9Db/mzt1WLqruZ9fUvmYrlpow1i4Z3tpkZ6N+3lzzu7xtl6R0Xa0X3G+e85KG/nS1nY2OG2HlQnWVX7O1zcrFCZ77HX9xspUb+h8v2zXrLzzBzvZ/ZoOVS3JflH7N2/6Q4FoSmcfT1Qs/3W0m39oi6e+terwSDQAAAACAiSYaAAAAAAATTTQAAAAAACaaaAAAAAAATDTRAAAAAACYaKIBAAAAADDRRAMAAAAAYKKJBgAAAADARBMNAAAAAIApU+oJvFNCLlfqKRRenC/1DHqHKPKzJXxOH9zwrJ19/6izrVyfPO6LJQQvVuLntOb+pVYuyviX97DspSOdThcTSHDemc99MUyc5513udCu9UWey7Eqrm9QHJV1m0vVVFv1wpsb/bGbmqxc+sQJds0oH1u50NJq14zXrLOzqaoqb/y2drtmNGm8V3N1gnn2q7SztikT7Wj+d+Z1L/JfbwpNzVbuz5983a758798l5WLNm2za0bl5XbWvS9KD+zv13Sv+QnWhnifdy5LksxsaGuzS6braq1clPaPp8E/WGbl9l84xa7Z/3eb7Wxuk5eNzz3drpla+YYZ9J+nePdeK3fc4w3dZnL5Fq02x+WVaAAAAAAATIma6LvuuktTpkxRbW2tamtrNWPGDP3yl7/s+P4FF1ygKIo6fd14440FnzQAACgO1noAALqW6Ne5R40apa997Ws64YQTFELQD37wA11++eVavny5TjnlFEnSDTfcoC9/+csd/02V+WtFAACg9FjrAQDoWqIm+rLLLuv073/8x3/UXXfdpaVLl3YsrFVVVRo+fHjhZggAAN4xrPUAAHTtiP8mOp/P6/7771dTU5NmzJjR8fi9996rwYMH69RTT9X8+fPV3Nz1myy0traqoaGh0xcAACi9Qq31Eus9AKDvSPzu3C+++KJmzJihlpYWVVdX68EHH9TJJ58sSbr22ms1duxYjRw5UitXrtTnPvc5rV69Wj/96U8PW2/BggW67bbbjnwLAABAQRV6rZdY7wEAfUfiJnrSpElasWKF6uvr9R//8R+67rrrtHjxYp188sn62Mc+1pE77bTTNGLECF100UVau3atJkw49MdDzJ8/X/Pmzev4d0NDg0aPHn0EmwIAAAqh0Gu9xHoPAOg7EjfR5eXlmjjx7c/hmzZtmp577jl961vf0ve+972DstOnT5ckrVmz5rALazabVTabTToNAABQJIVe6yXWewBA33HUnxMdx7FaW1sP+b0VK1ZIkkaMGHG0wwAAgBJhrQcA4A8SvRI9f/58zZkzR2PGjFFjY6Puu+8+LVq0SI8++qjWrl2r++67T5deeqkGDRqklStX6uabb9b555+vKVOmFGv+AACggFjrAQDoWqImevv27frIRz6iLVu2qK6uTlOmTNGjjz6q9773vdqwYYN+85vf6Jvf/Kaampo0evRoXXXVVbrllluOaGItl0xTpqyi21zFz3/nFTz7NH/w373oZ11R5OVCKPzYCUQZ/5AIuZyVS/XrZ9eMm5rsrC3BcxqVlXsl29uOdDaH9f5RZxe8ZhKtl55lZ7O/eK7wEyjCOZJK8Nm1sfHuwkXjbrtkb797fkqSUmk/G+e9XBGuZUn2Z2jzztHWi063crlci/Sbh+zxe7N3cq2XpKbZp1nrfb+fLbfqtbx3qj125aKXrFzUsM+uGdXVWrn8/m12zVSCX4MPh/mNgT+VHjPKrplfvc7KRZOPt2vGL6+1cqnK7o+NA9LrttpZTRzn5Xbstku6152fTfV/ayNVu90b29zvkrRvtn9PXP3LF6xcVFNj14wqvHutdK13LklSGDPSzuqN9VYsqq72a5r3j0nuifM7d1m5isWr7JoaPtSOpvvXWbnU86/aNWPz3iA6YbxdM9XiHfv7RnV/D5FrT0m/98ZN1ER///vfP+z3Ro8ercWLFycpBwAAehjWegAAunbUfxMNAAAAAMCxgiYaAAAAAAATTTQAAAAAACaaaAAAAAAATDTRAAAAAACYaKIBAAAAADDRRAMAAAAAYKKJBgAAAADAlCn1BA6n4pFlykRl3QejyCv4uxePbkJH6Rcbl1m5S487oyjjRxlvV4dcruBjx01NBa9ZLKG9rdRTKJnsL54r7QRCKHjJuLm54DWLogjbnkicL+34pmLsz/JHn7dyqdBe8LHxtqqfL7fW+9y7p1r1+r201R4719Jq5UKbvzb865onrNy8yRfaNaPycjvb/N4pVq7ykRV2zfTIYVYu98Irds0om7VyIcH1MWrzz9OwyTtOkjz3SpmvTYXYLhnv8+6hQrt//1azaoedDeY2RRXe/pSk/HZv/FRVlV0z2rjFH3//fiuXrqu1a8YNDV7NwYPsmqnKCiuXr/fGlqSwZZs/fnU/KxeNHmnXjHbssnLhrU12zdDunff9jGM0l/fWBIlXogEAAAAAsNFEAwAAAABgookGAAAAAMBEEw0AAAAAgIkmGgAAAAAAE000AAAAAAAmmmgAAAAAAEw00QAAAAAAmGiiAQAAAAAw0UQDAAAAAGDKlHoCRyszbKiVy23dVuSZdO3Px57tBVPBrpkeMsjOhub9Xq6x0a6ZOW6klctt2mzXLLWorNzKhfa2Igwe+dngHydFkUp7uThf3HmUQKqmxs7GCc4n17ofTbVy4695oeBjJ5EeMMDO5vfsKeJM0NNF6bSiqPtrSqrFu56E+gZ77HRttZWL97fYNf/uwmutXGqEfx3PDauzs1XrzetOeZlds32Ud78Rrd9o10xVVli50NJq11RVpR2NhnrbFN7ytynqV2XlUnW1ds14t3d9TFX3s2uGTVvtbGrYECsX79xt17Tl/XuIuLnZzqYHeutTGD3crpnatMOrad6PS9LWq0+2csPuXWXXjCq8806SlMtZsbjWP+9Se737bLX7+zNyj/2t3e+jKPbv73klGgAAAAAAE000AAAAAAAmmmgAAAAAAEw00QAAAAAAmGiiAQAAAAAw0UQDAAAAAGCiiQYAAAAAwEQTDQAAAACAiSYaAAAAAABTptQTOFqv3H6clTvhI9uKPJOuhVzOC0aRX7O+wc7GLS121pXbtLngNUsttLdZuSjjnzr2vg/Brnksi8/7MzubenK5X9g89+LGRr+mO3SC42n8NS8UfPxEzplixfJLVxZ5IugrUrXVSqXKu82tv7CfVW/8m5X22PG+JjOY4Pq831xvs91v8wFR3h8/2rrLysVt7XbN9Mq1Vi6U+9sU3PHLyuya8a7ddlZmNjVpgl0yvLnRysUN++yaqdpqL5jPJ6hZY2dDJu3V7Fdl15Q5/q4LxtglB/znCn/8AXVebu0Gu2Qwn/9o3Ci75tB/e84LVvrXvJDgHmbv+0+3cgMeWW3XdO+h0sOH2TXdfiQyrk9x8K+LvBINAAAAAICJJhoAAAAAABNNNAAAAAAAJppoAAAAAABMNNEAAAAAAJhoogEAAAAAMNFEAwAAAABgookGAAAAAMBEEw0AAAAAgClT6gn8qRCCJCmndil0n4/3t1h1c6H9aKb1DorsZCr42bjXbH/vEAXj4PxvIeSKOJMSCbGZyxd86DjnnfOSlEp03JvnU4J9b4/cm44n9/nvY9ecnN7enlCE/X+s6ljv4zYrn28113uzniTFwcuGBMdzcMeP/WMpn09w3TPHT3JfEJn3G0mep8hdH0LarplkfFcq35pgfPd48q/j7v5Mst5Gsf8aWsh7rUKU4LxT5I2fb/OP+5z53EtSZO5Td3++Hfaef3dsyT9HowTnSJK1Od/u9lhJrrne+CH2nye3x3OuYwdqOWt9FHrYHcHGjRs1evToUk8DAICDbNiwQaNGjSr1NPoE1nsAQE/krPU9romO41ibN29WTU2NougPPzFoaGjQ6NGjtWHDBtXW1pZwhoXR17ZHYpt6C7apd2CbepYQghobGzVy5EilUvwlVCEcar3vzcfI4bBNPV9f2x6Jbeot2KaeJcla3+N+nTuVSnXZ+dfW1va6HdKVvrY9EtvUW7BNvQPb1HPU1dWVegp9SlfrfW89RrrCNvV8fW17JLapt2Cbeg53refH6QAAAAAAmGiiAQAAAAAw9ZomOpvN6ktf+pKy2Wypp1IQfW17JLapt2Cbege2CceivniMsE09X1/bHolt6i3Ypt6rx72xGAAAAAAAPVWveSUaAAAAAIBSo4kGAAAAAMBEEw0AAAAAgIkmGgAAAAAAE000AAAAAACmXtFEL1y4UOPGjVNFRYWmT5+u3/3ud6We0hG79dZbFUVRp6/JkyeXelqJPPHEE7rssss0cuRIRVGkhx56qNP3Qwj64he/qBEjRqiyslKzZs3S66+/XprJmrrbpuuvv/6g/XbJJZeUZrKGBQsW6KyzzlJNTY2GDh2qK664QqtXr+6UaWlp0dy5czVo0CBVV1frqquu0rZt20o04+4523TBBRcctJ9uvPHGEs24e3fddZemTJmi2tpa1dbWasaMGfrlL3/Z8f3eto+k7rept+0jvHNY63sW1vqev9ZLfW+9Z63v2fvnANb6XtBE//jHP9a8efP0pS99Sb///e81depUzZ49W9u3by/11I7YKaecoi1btnR8PfXUU6WeUiJNTU2aOnWqFi5ceMjv33777brzzjv13e9+V88++6z69eun2bNnq6Wl5R2eqa+7bZKkSy65pNN++9GPfvQOzjCZxYsXa+7cuVq6dKl+/etfq729XRdffLGampo6MjfffLN+9rOf6YEHHtDixYu1efNmXXnllSWcddecbZKkG264odN+uv3220s04+6NGjVKX/va17Rs2TI9//zzuvDCC3X55ZfrpZdektT79pHU/TZJvWsf4Z3BWt/zsNb3/LVe6nvrPWt9z94/B7DWSwo93Nlnnx3mzp3b8e98Ph9GjhwZFixYUMJZHbkvfelLYerUqaWeRsFICg8++GDHv+M4DsOHDw933HFHx2N79+4N2Ww2/OhHPyrBDJP7020KIYTrrrsuXH755SWZTyFs3749SAqLFy8OIby9T8rKysIDDzzQkXnllVeCpLBkyZJSTTORP92mEEJ497vfHf7n//yfpZtUAQwYMCD827/9W5/YRwcc2KYQ+sY+QuGx1vdsrPW9R19b71nre49jba3v0a9Et7W1admyZZo1a1bHY6lUSrNmzdKSJUtKOLOj8/rrr2vkyJE6/vjj9aEPfUjr168v9ZQKZt26ddq6dWunfVZXV6fp06f36n0mSYsWLdLQoUM1adIkffzjH9euXbtKPSVbfX29JGngwIGSpGXLlqm9vb3Tfpo8ebLGjBnTa/bTn27TAffee68GDx6sU089VfPnz1dzc3MpppdYPp/X/fffr6amJs2YMaNP7KM/3aYDeus+QnGw1vc+rPU9V19b71nre75jda3PlHoCXdm5c6fy+byGDRvW6fFhw4bp1VdfLdGsjs706dN1zz33aNKkSdqyZYtuu+02nXfeeVq1apVqampKPb2jtnXrVkk65D478L3e6JJLLtGVV16p8ePHa+3atfr7v/97zZkzR0uWLFE6nS719LoUx7E+9alP6V3vepdOPfVUSW/vp/LycvXv379Ttrfsp0NtkyRde+21Gjt2rEaOHKmVK1fqc5/7nFavXq2f/vSnJZxt11588UXNmDFDLS0tqq6u1oMPPqiTTz5ZK1as6LX76HDbJPXOfYTiYq3vfVjre6a+tt6z1vfs/XOsr/U9uonui+bMmdPx/6dMmaLp06dr7Nix+slPfqKPfvSjJZwZunL11Vd3/P/TTjtNU6ZM0YQJE7Ro0SJddNFFJZxZ9+bOnatVq1b1ur/H68rhtuljH/tYx/8/7bTTNGLECF100UVau3atJkyY8E5P0zJp0iStWLFC9fX1+o//+A9dd911Wrx4camndVQOt00nn3xyr9xHQFKs9b1Tb17rpb633rPW92zH+lrfo3+de/DgwUqn0we9Q922bds0fPjwEs2qsPr3768TTzxRa9asKfVUCuLAfunL+0ySjj/+eA0ePLjH77ebbrpJP//5z/X4449r1KhRHY8PHz5cbW1t2rt3b6d8b9hPh9umQ5k+fbok9ej9VF5erokTJ2ratGlasGCBpk6dqm9961u9eh8dbpsOpTfsIxQXa33vw1rf8/S19Z61vmfvH4m1vkc30eXl5Zo2bZoee+yxjsfiONZjjz3W6Xfue7N9+/Zp7dq1GjFiRKmnUhDjx4/X8OHDO+2zhoYGPfvss31mn0nSxo0btWvXrh6730IIuummm/Tggw/qt7/9rcaPH9/p+9OmTVNZWVmn/bR69WqtX7++x+6n7rbpUFasWCFJPXY/HUocx2ptbe2V++hwDmzTofTGfYTCYq3vfVjre46+tt6z1vfs/dOVY26tL+37mnXv/vvvD9lsNtxzzz3h5ZdfDh/72MdC//79w9atW0s9tSPy6U9/OixatCisW7cuPP3002HWrFlh8ODBYfv27aWemq2xsTEsX748LF++PEgK3/jGN8Ly5cvDW2+9FUII4Wtf+1ro379/ePjhh8PKlSvD5ZdfHsaPHx/2799f4pkfXlfb1NjYGP7u7/4uLFmyJKxbty785je/CWeccUY44YQTQktLS6mnfkgf//jHQ11dXVi0aFHYsmVLx1dzc3NH5sYbbwxjxowJv/3tb8Pzzz8fZsyYEWbMmFHCWXetu21as2ZN+PKXvxyef/75sG7duvDwww+H448/Ppx//vklnvnhff7znw+LFy8O69atCytXrgyf//znQxRF4Ve/+lUIofftoxC63qbeuI/wzmCt73lY63v+Wh9C31vvWet79v45gLU+hB7fRIcQwre//e0wZsyYUF5eHs4+++ywdOnSUk/piH3wgx8MI0aMCOXl5eG4444LH/zgB8OaNWtKPa1EHn/88SDpoK/rrrsuhPD2R1984QtfCMOGDQvZbDZcdNFFYfXq1aWddDe62qbm5uZw8cUXhyFDhoSysrIwduzYcMMNN/Tom7tDbYukcPfdd3dk9u/fHz7xiU+EAQMGhKqqqvD+978/bNmypXST7kZ327R+/fpw/vnnh4EDB4ZsNhsmTpwYPvOZz4T6+vrSTrwLf/3Xfx3Gjh0bysvLw5AhQ8JFF13UsaiG0Pv2UQhdb1Nv3Ed457DW9yys9T1/rQ+h7633rPU9e/8cwFofQhRCCIV/fRsAAAAAgL6nR/9NNAAAAAAAPQlNNAAAAAAAJppoAAAAAABMNNEAAAAAAJhoogEAAAAAMNFEAwAAAABgookGAAAAAMBEEw0AAAAAgIkmGgAAAAAAE000AAAAAAAmmmgAAAAAAEz/PyI/vuo8TxBjAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In the transformer architecture the matrix W of size (context_size, context_size) is not a raw parameter,\n",
    "# but rather the result of some computations.\n",
    "# The matrix X_e, of size (context_size, emb_size) where each row is a token in the space of size emb_size\n",
    "# is first projected  into a smaller space of size head_size. \n",
    "# This projection is a actually repeated three times to obtain matrices with different meanings:\n",
    "#   - The rows of the matrix K represent the information with which a token should be indexed\n",
    "#   - The rows of the matrix Q represent the information that a token is interested in\n",
    "#   - The rows of the matrix V are projections of X_e that contains the info to be shareds\n",
    "#\n",
    "# When multiplying  matrix K of size (context_size, emb_size) and the transposse of Q\n",
    "# of size (context_size, emb_size) we obtain a matrix of size (context_size, context_size)\n",
    "# where the element at position (i,j) represents the amount of information that needs to be\n",
    "# shared from token at position j to the token at position i.\n",
    "# This matrix has the same shape and function as the matrix W discussed before.\n",
    "# Adding a softmax operation we can obtain a matrix where each row is a probability distribution,\n",
    "# and the element (i,j) gives us exactly the fraction of the token j that we want to transfer \n",
    "# to the token i.\n",
    "#\n",
    "# The last steps to perform is multilplying the self-attention matrix W by the input to operate the transfer \n",
    "# of information among tokens.\n",
    "# This operation is performed in a space of size head_size, using the projected matrix V, \n",
    "# instead of the original matrix X_e.\n",
    "#\n",
    "#  The result of the attention mechanism is thus:\n",
    "#   Z = softmax(Q x K.T) x V\n",
    "#\n",
    "#  The only detail remaining is the the normalization of the (Q x K.T) matrix to insure that the rows have unit variance.\n",
    "#  If it's not the case (Q x K.T) might contain values that have large magnitude, and after applying the softmax\n",
    "#  operation, the result will tend be a one-hot vector where only 1 or a few elemnts are different from zero,\n",
    "#  while the otheres will be virtually zero.\n",
    "#  Under this situation the attention mechanism will be greatly compromised, as a token will receive information\n",
    "#  only from a handful of tokens in the context.\n",
    "# Ex\n",
    "\n",
    "context_size = 40\n",
    "head_size = 10\n",
    "\n",
    "# Generating Q and k\n",
    "Q = torch.randn(context_size, head_size)\n",
    "print(f'Q.shape = {Q.shape}')\n",
    "K = torch.randn(context_size, head_size)\n",
    "print(f'K.shape = {K.shape}')\n",
    "\n",
    "\n",
    "# Multiplying the Q and K to obtain the W matrix\n",
    "W = Q @ K.T\n",
    "print(f'W.shape = {W.shape}')\n",
    "\n",
    "# Normalizing with sqrt(head_size)\n",
    "W_norm  = W / head_size**0.5\n",
    "\n",
    "# Compting softmax of bot original and normalized\n",
    "W_soft = W.softmax(axis=1)\n",
    "W_norm_soft = W_norm.softmax(axis=1)\n",
    "\n",
    "# Comparing the weight distribution with, and without normalization\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "ax0.set_title('W without norm')\n",
    "ax0.imshow(W_soft)\n",
    "ax1.set_title('W with Norm')\n",
    "ax1.imshow(W_norm_soft)\n",
    "\n",
    "\n",
    "'''\n",
    "a = torch.randn(50,100)\n",
    "print(a.std(axis= 1).mean())\n",
    "b = torch.randn(50,100)\n",
    "print(b.std(axis= 1).mean())\n",
    "ab = (a @ b.T) \n",
    "print(ab.std(axis= 1).mean())\n",
    "ab_norm = ab * 100**-0.5\n",
    "print(ab_norm.std(axis= 1).mean())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "35993ded-d06c-47a5-9df7-7fe302d76ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts next character using all previous characters\n",
    "\n",
    "class TransformerLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, emb_size, block_size, head_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block_size = block_size\n",
    "\n",
    "        # A table mapping the index of each character, to an embedding vector X_e_0 of size emb_size\n",
    "        self.E = nn.Embedding(vocab_size, emb_size)\n",
    "\n",
    "        # # A table mapping the position of each character, to an embedding vector X_e_0 of size emb_size\n",
    "        self.P = nn.Embedding(block_size, emb_size)\n",
    "\n",
    "        # The transformations mapping X_e to a space of size head_size.\n",
    "        # X_e is a \"private\" representation of a token.\n",
    "        # From this vector we can project different  representations\n",
    "        #   - K => represents the information that X_e could provide (KEY)\n",
    "        #   - Q => represents the information that X_e might require (QUERY)\n",
    "        #   - V => represents the information that X_e will actually provide (VALUE)\n",
    "        self.W_k = nn.Linear(emb_size, head_size)\n",
    "        self.W_q = nn.Linear(emb_size, head_size)\n",
    "        self.W_v = nn.Linear(emb_size, head_size)\n",
    "        \n",
    "        # Output layer to produce the logits\n",
    "        self.output_layer = nn.Linear(head_size, vocab_size)\n",
    "        \n",
    "\n",
    "    def forward(self, X, y=None):\n",
    "\n",
    "        # Transforming the input indices to embedding vectors\n",
    "        # The shape of the input is (batch_size, block_size)\n",
    "        # The shape of the output is (batch_size, block_size, emb_size)\n",
    "        X_e_0 = self.E(X)\n",
    "\n",
    "        # Transforming the input indices to embedding vectors\n",
    "        # The shape of the input is (block_size)\n",
    "        # The shape of the output is (block_size, emb_size)\n",
    "        X_pos = torch.arange(0, self.block_size)  # creating matrix with positions: [0, 1, ...]\n",
    "        X_e_1 = self.P(X_pos)   \n",
    "\n",
    "        # Adding together the embedding vectors\n",
    "        # The shape of X_e_0 is (batch_size, block_size, emb_size)\n",
    "        # The shape of X_e_1 is  (block_size, emb_size)\n",
    "        # (Broadcasting will make the operation possible)\n",
    "        # The shape of the output is (batch_size, block_size, emb_size)\n",
    "        X_e = X_e_0 + X_e_1\n",
    "\n",
    "\n",
    "        # Projecting the embedding vector X_e to obtain K, Q, V in the space of size head_size\n",
    "        K = self.W_k(X_e)\n",
    "        Q = self.W_q(X_e)\n",
    "        V = self.W_v(X_e)\n",
    "\n",
    "        # Matrix providing the attention mechanism\n",
    "        # - It is obtained comparing one by one, the rows of K with the rows of Q\n",
    "        # - The scalar product between the i-th row of K and j-th row of Q represents\n",
    "        #   the 'affinity' between the token at position i and the token at position j\n",
    "        # - We divide by sqrt(emb_size) to ensure that the rows have unit variance\n",
    "        # - We mask it with a triangular matrix to avoid contamination from tokens \n",
    "        #   in the future\n",
    "        W  = torch.tril(Q @ K.transpose(1,2))  # we transpose only the last 2 dims. 1st dim is batch \n",
    "        W /= W.sum(axis=1, keepdims=True)\n",
    "        W[W == 0.] = -torch.inf\n",
    "\n",
    "        # Applying attention mechanism to get info from previous steps in the block\n",
    "        # The mechanism is applied to the projection V\n",
    "        X_a = W.softmax(axis=1) @ V\n",
    "        \n",
    "        # Extracting the logits of the next character, for each character in the input\n",
    "        # The shape of the input is (batch_size, block_size, emb_size)\n",
    "        # The shape of the output is (batch_size, block_size, vocab_size)\n",
    "        logits = self.output_layer(X_a)\n",
    "\n",
    "        # computing loss, only when a target y is provided\n",
    "        if y is not None:\n",
    "            # reshaping logits, and target to match the expected shapes of the cross_entropy function\n",
    "            batch_size, block_size, vocab_size = logits.shape\n",
    "            logits = logits.view((batch_size*block_size, vocab_size))\n",
    "            y = y.view(batch_size*block_size)\n",
    "            \n",
    "            # computing the loss\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "        else:\n",
    "            loss = None\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, X, max_length=100):\n",
    "\n",
    "        # initilizing the result\n",
    "        res = X.clone()\n",
    "\n",
    "        for i in range(max_length):\n",
    "            # performing a forward pass\n",
    "            logits, loss = self.forward(X)\n",
    "    \n",
    "            # condsidering only the last character of each sequence\n",
    "            logits = logits[:, -1, :]\n",
    "    \n",
    "            # computing probs, from the logits\n",
    "            probs = logits.softmax(dim=-1)\n",
    "    \n",
    "            # sampling from the probability distributions\n",
    "            new_element = torch.multinomial(probs, 1)\n",
    "    \n",
    "            # attaching the new elements to the context\n",
    "            # and excluding the oldest element\n",
    "            X = torch.concat((X[:, 1:], new_element), axis=1)\n",
    "\n",
    "            # Storing the generated element\n",
    "            res = torch.concat((res, new_element), axis=1)\n",
    "\n",
    "        # Decoding the generated sequences\n",
    "        res = [decode(res[i].tolist()) for i in range(res.shape[0]) ]\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "b029c013-ed66-47dc-bce3-67c7aed3e549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 65]), tensor(4.2521, grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_size = 32\n",
    "head_size = 16\n",
    "m1 = TransformerLanguageModel(vocab_size, emb_size, block_size, head_size)\n",
    "logits, loss = m1(x_train, y_train)\n",
    "logits.shape, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "b4a1eac8-4059-4614-ab98-d50f883970cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0635299682617188\n",
      "3.199181318283081\n",
      "3.0119805335998535\n",
      "2.7662734985351562\n",
      "2.8942482471466064\n",
      "2.9732120037078857\n",
      "2.321126937866211\n",
      "2.5919036865234375\n",
      "2.54081392288208\n",
      "2.6982009410858154\n"
     ]
    }
   ],
   "source": [
    "# Training a model with Adam Optimizer\n",
    "optimizer1 = torch.optim.Adam(m1.parameters(), lr=10**(-3))\n",
    "\n",
    "steps = 100000\n",
    "for i in range(steps):\n",
    "\n",
    "    # generating a random batch\n",
    "    X_b, y_b = get_batch(data_train, batch_size, block_size)\n",
    "\n",
    "    # forward pass\n",
    "    logits, loss = m1(X_b, y_b)\n",
    "\n",
    "    # bacward pass\n",
    "    optimizer1.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "\n",
    "    # printing at 10% intervals\n",
    "    if i % int(steps / 10) == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "1dc43da8-3e0f-4825-89d3-8535363e8f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LALDBUCE:\n",
      "TSextotur.\n",
      "\n",
      "QUESENO:\n",
      "WAMNIUS:\n",
      "OLANUT:\n",
      "HAs!\n",
      "F RIORI:\n",
      "Y:\n",
      "B\n",
      "Frot athe ize emat anpry ourscofuthe ancer fello me mbeigclane.\n",
      "To hend atind me way thewine'ss, t hislis, ont hetes psatithe imens:\n",
      "\n",
      "Fretre me hom evine dextewe anghat eringe cemer inche my of, wero wacthe orfer mor omy thatis, me w\n"
     ]
    }
   ],
   "source": [
    "# Generating sequence from TRAINED model\n",
    "\n",
    "# creating initial context\n",
    "context = torch.zeros((1, block_size)).int()\n",
    "\n",
    "# generating sequence of arbitrary length \n",
    "res = m1.generate(context, max_length=300)\n",
    "\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e076a-9a79-4812-96b3-80d6b7df3ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
